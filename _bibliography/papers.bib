---
---

@string{aps = {American Physical Society,}}

@inproceedings{kaliosis-etal-2025-fada,
    abbr={EMNLP},
    title = {Learning to Align: Addressing Character Frequency Distribution Shifts in Handwritten Text Recognition},
    author = {Kaliosis, Panagiotis and Pavlopoulos, John},
    booktitle = {Findings of the Empirical Methods in Natural Language Processing: EMNLP 2025},
    month = {November},
    year = {2025},
    location = {Suzhou, China},
    publisher = "Association for Computational Linguistics",
    url={https://arxiv.org/pdf/2506.09846},
    google_scholar_id={WF5omc3nYNoC},
    selected={true},
    annotation={Work started while an intern of Archimedes AI Research Hub},
    pdf={https://arxiv.org/pdf/2506.09846},
    venue={EMNLP},
    additional_info={. Our code will soon be made available [here](https://github.com/pkaliosis/fada)},
    abstract={Handwritten text recognition aims to convert visual input into machine-readable text, and it remains challenging due to the evolving and context-dependent nature of handwriting. Character sets change over time, and character frequency distributions shift across historical periods or regions, often causing models trained on broad, heterogeneous corpora to underperform on specific subsets. To tackle this, we propose a novel loss function that incorporates the Wasserstein distance between the character frequency distribution of the predicted text and a target distribution empirically derived from training data. By penalizing divergence from expected distributions, our approach enhances both accuracy and robustness under temporal and contextual intra-dataset shifts. Furthermore, we demonstrate that character distribution alignment can also improve existing models at inference time without requiring retraining by integrating it as a scoring function in a guided decoding scheme. Experimental results across multiple datasets and architectures confirm the effectiveness of our method in boosting generalization and performance. We open source our code at https://github.com/pkaliosis/fada.}
}

@inproceedings{wang-etal-2025-overhearing,
    abbr={EMNLP},
    title = {LVLMs are Bad at Overhearing Human Referential Communication},
    author = {Wang, Zhengxiang and Li, Weiling and Kaliosis, Panagiotis and Rambow, Owen and Brennan, Susan},
    booktitle = {Findings of the Empirical Methods in Natural Language Processing: EMNLP 2025},
    month = {November},
    year = {2025},
    location = {Suzhou, China},
    publisher = "Association for Computational Linguistics",
    url={https://arxiv.org/abs/2509.11514},
    google_scholar_id={WF5omc3nYNoC},
    selected={true},
    pdf={https://arxiv.org/abs/2509.11514},
    venue={EMNLP},
    additional_info={. Our code will soon be made available [here](https://github.com/jaaack-wang/lvlms-overhearing)},
    abstract={During spontaneous conversations, speakers collaborate on novel referring expressions, which they can then re-use in subsequent conversations. Understanding such referring expressions is an important ability for an embodied agent, so that it can carry out tasks in the real world. This requires integrating and understanding language, vision, and conversational interaction. We study the capabilities of seven state-of-the-art Large Vision Language Models (LVLMs) as overhearers to a corpus of spontaneous conversations between pairs of human discourse participants engaged in a collaborative object-matching task. We find that such a task remains challenging for current LVLMs and they all fail to show a consistent performance improvement as they overhear more conversations from the same discourse participants repeating the same task for multiple rounds. We release our corpus and code for reproducibility and to facilitate future research.}
}

@inproceedings{kaliosis-etal-2024-data,
    abbr={ACL},
    title = {A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning},
    author = {Kaliosis, Panagiotis  and Pavlopoulos, John  and
      Charalampakos, Foivos  and
      Moschovis, Georgios  and
      Androutsopoulos, Ion},
    booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
    month = {August},
    year = {2024},
    location = {Bangkok, Thailand},
    publisher = "Association for Computational Linguistics",
    url={https://aclanthology.org/2024.findings-acl.444/},
    doi={10.18653/v1/2024.findings-acl.444},
    pages = {7450--7466},
    google_scholar_id={UeHWp8X0CEIC},
    selected={true},
    annotation={Work done while a member of AUEB and Archimedes AI Research Hub},
    pdf={https://arxiv.org/pdf/2406.14164},
    venue={ACL},
    additional_info={. Our code is available [here](https://github.com/nlpaueb/dmmcs)},
    abstract={Diagnostic Captioning (DC) automatically generates a diagnostic text from one or more medical images (e.g., X-rays, MRIs) of a patient. Treated as a draft, the generated text may assist clinicians, by providing an initial estimation of the patient's condition, speeding up and helping safeguard the diagnostic process. The accuracy of a diagnostic text, however, strongly depends on how well the key medical conditions depicted in the images are expressed. We propose a new data-driven guided decoding method that incorporates medical information, in the form of existing tags capturing key conditions of the image(s), into the beam search of the diagnostic text generation process. We evaluate the proposed method on two medical datasets using four DC systems that range from generic image-to-text systems with CNN encoders and RNN decoders to pre-trained Large Language Models. The latter can also be used in few- and zero-shot learning scenarios. In most cases, the proposed mechanism improves performance with respect to all evaluation measures. We provide an open-source implementation of the proposed method at https://github.com/nlpaueb/dmmcs.}
}

@inproceedings{10627012,
  abbr={ICASSP},
  author={Kaliosis, Panagiotis and Eleftheriou, Sofia and Nikou, Christos and Giannakopoulos, Theodoros},
  booktitle={2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, 
  title={A Self-Supervised Learning Approach for Detecting Non-Psychotic Relapses Using Wearable-Based Digital Phenotyping}, 
  year={2024},
  volume={},
  number={},
  venue={ICASSP},
  pages={97-98},
  url={https://ieeexplore.ieee.org/abstract/document/10627012},
  doi={10.1109/ICASSPW62465.2024.10627012},
  abstract={We present MagCIL’s approach for the 1st track of the "2nd e-Prevention challenge: Psychotic and Non-Psychotic Relapse Detection using Wearable-Based Digital Phenotyping". First we present our approach for preprocessing and extracting features from the wearable’s raw data. We then propose a Transformer model for learning self-supervised representations from augmented features, trained on data from non-relapse days from each of the 9 patients of the challenge. We adopt two unsupervised methods for detecting relapse days as outliers. A separate unsupervised model is tuned for each patient using the validation data of the challenge. Our method ranked second with ROCAUC = 0.651 and PRAUC = 0.642 on the final test dataset of the challenge. The respective code is available at this repository.},
  location={Seoul, South Korea},
  month={April},
  google_scholar_id={zYLM7Y9cAGgC},
  selected={true},
  annotation={Work done while a member of the Computational Intelligence Laboratory of NCSR Demokritos},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10627012},
  additional_info={. Our code is available [here](https://github.com/magcil/e-prevention-challenge)}
  }

  @inproceedings{10.1145/3688671.3688771,
    author = {Gkritzali, Evangelia and Kaliosis, Panagiotis and Galanaki, Sofia and Palogiannidi, Elisavet and Giannakopoulos, Theodoros},
    title = {Greek2MathTex: A Greek Speech-to-Text Framework for LaTeX Equations Generation},
    year = {2024},
    isbn = {9798400709821},
    booktitle={Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3688671.3688771},
    doi = {10.1145/3688671.3688771},
    abstract = {In the vast majority of the academic and scientific domains, LaTeX has established itself as the de facto standard for typesetting complex mathematical equations and formulae. However, LaTeX \'{s} complex syntax and code-like appearance present accessibility barriers for individuals with disabilities, as well as those unfamiliar with coding conventions. In this paper, we present a novel solution to this challenge through the development of a novel speech-to- LaTeX equations system specifically designed for the Greek language. We propose an end-to-end system that harnesses the power of Automatic Speech Recognition (ASR) and Natural Language Processing (NLP) techniques to enable users to verbally dictate mathematical expressions and equations in natural language, which are subsequently converted into LaTeX format. We present the architecture and design principles of our system, highlighting key components such as the ASR engine, the LLM-based prompt-driven equations generation mechanism, as well as the application of a custom evaluation metric employed throughout the development process. We have made our system open source and available at https://github.com/magcil/greek-speech-to-math.},
    booktitle = {Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
    articleno = {19},
    numpages = {4},
    keywords = {Automatic Speech Recognition, Natural Language Processing, Accessibility, Equations},
    abbr = {SETN},
    annotation={Work done while a member of the Computational Intelligence Laboratory of NCSR Demokritos},
    selected={True},
    location={Piraeus, Greece},
    google_scholar_id={Tyk-4Ss8FVUC},
    additional_info={. Our code is available [here](https://github.com/magcil/greek-speech-to-math)}
  }

  @inproceedings{DBLP:conf/clef/KaliosisMCPA23,
  abbr={CLEF 2023},
  author={Panagiotis Kaliosis and Georgios Moschovis and Foivos Charalampakos and John Pavlopoulos and Ion Androutsopoulos},
  title={AUEB NLP Group at ImageCLEFmedical Caption 2023},
  year={2023},
  cdate={1672531200000},
  pages={1524-1548},
  url={https://ceur-ws.org/Vol-3497/paper-126.pdf},
  booktitle={Conference and Labs of the Evaluation Forum (Working Notes)},
  crossref={conf/clef/2023w},
  abstract={This article describes the methods that the AUEB NLP Group experimented with during its participation in the 7th edition of the ImageCLEFmedical Caption sub-tasks, namely Concept Detection and Caption Prediction. The former intends to automatically classify biomedical images into a set of one or more tags based solely on the visual input, while the latter aims to generate a syntactically and semantically accurate diagnostic caption that addresses the medical conditions depicted on a given image. For the Concept Detection sub-task, extending our previous work, we utilized a wide range of Convolutional Neural Network encoders followed by a Feed-Forward Neural Network, both in a single-task and a multi-task fashion, as well as combined with a contrastive learning approach. Our methods concerning the Caption Prediction sub-task are influenced by both our previous work and recent progress in Natural Language Processing (NLP) methods. Our two base systems use CNN-RNN and Transformer-to-Transformer encoder-decoder architectures, respectively. Additionally, we experimented with a Transformer-based denoising component, which was trained to reformulate the generated captions in a more syntactically coherent and medically accurate way. Our group ranked 1st in Concept Detection and 3rd in Caption Prediction.},
  location={Thessaloniki, Greece},
  annotation={Work done while a member of the the NLP Group of AUEB},
  google_scholar_id={2osOgNQ5qMEC},
  selected={True}

}